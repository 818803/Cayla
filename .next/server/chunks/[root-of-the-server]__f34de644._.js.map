{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 60, "column": 0}, "map": {"version":3,"sources":["file:///Users/plana/Desktop/test/src/lib/ai-provider.ts"],"sourcesContent":["// lib/ai-providers.ts\nexport interface ChatMessage {\n  role: 'user' | 'assistant' | 'system';\n  content: string;\n}\n\nexport interface AIResponse {\n  message: string;\n  error?: string;\n  provider?: string;\n}\n\n// OpenAI Integration\nexport class OpenAIService {\n  private apiKey: string;\n  private baseUrl: string = 'https://api.openai.com/v1';\n\n  constructor(apiKey: string) {\n    this.apiKey = apiKey;\n  }\n\n  async generateResponse(\n    messages: ChatMessage[],\n    model: string = 'gpt-3.5-turbo'\n  ): Promise<AIResponse> {\n    try {\n      const response = await fetch(`${this.baseUrl}/chat/completions`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${this.apiKey}`,\n        },\n        body: JSON.stringify({\n          model: model,\n          messages: messages,\n          max_tokens: 1000,\n          temperature: 0.7,\n          stream: false,\n        }),\n      });\n\n      if (!response.ok) {\n        const errorData = await response.json().catch(() => ({}));\n        const errorMessage = errorData.error?.message || `Unknown error with status ${response.status}`;\n        console.error(`OpenAI API Error: ${response.status}`, errorData);\n\n        if (response.status === 401) {\n            return { message: \"Authentication error. Please check your OpenAI API key.\", error: \"Invalid API Key\", provider: \"OpenAI\" };\n        }\n        if (response.status === 429) {\n            return { message: \"I'm receiving too many requests right now. Please try again in a moment.\", error: \"Rate limit exceeded\", provider: \"OpenAI\" };\n        }\n\n        throw new Error(`OpenAI API Error: ${response.status} - ${errorMessage}`);\n      }\n\n      const data = await response.json();\n      return {\n        message: data.choices[0].message.content,\n        provider: 'OpenAI',\n      };\n    } catch (error) {\n      console.error('OpenAI API Error:', error);\n      return {\n        message: 'Sorry, I had trouble connecting. Please try again in a moment.',\n        error: error instanceof Error ? error.message : 'Unknown error',\n        provider: 'OpenAI',\n      };\n    }\n  }\n\n  // For streaming responses (optional)\n  async generateStreamResponse(\n    messages: ChatMessage[],\n    onChunk: (chunk: string) => void,\n    model: string = 'gpt-3.5-turbo'\n  ): Promise<AIResponse> {\n    try {\n      const response = await fetch(`${this.baseUrl}/chat/completions`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n          'Authorization': `Bearer ${this.apiKey}`,\n        },\n        body: JSON.stringify({\n          model: model,\n          messages: messages,\n          max_tokens: 1000,\n          temperature: 0.7,\n          stream: true,\n        }),\n      });\n\n      if (!response.ok) {\n        throw new Error(`OpenAI API Error: ${response.status}`);\n      }\n\n      const reader = response.body?.getReader();\n      if (!reader) throw new Error('No response body');\n\n      let fullMessage = '';\n      \n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        const chunk = new TextDecoder().decode(value);\n        const lines = chunk.split('\\n').filter(line => line.trim());\n\n        for (const line of lines) {\n          if (line.startsWith('data: ')) {\n            const data = line.slice(6);\n            if (data === '[DONE]') continue;\n\n            try {\n              const parsed = JSON.parse(data);\n              const content = parsed.choices[0]?.delta?.content;\n              if (content) {\n                fullMessage += content;\n                onChunk(content);\n              }\n            } catch (e) {\n              // Skip invalid JSON\n            }\n          }\n        }\n      }\n\n      return {\n        message: fullMessage,\n        provider: 'OpenAI',\n      };\n    } catch (error) {\n      console.error('OpenAI Streaming Error:', error);\n      return {\n        message: 'Sorry, I encountered an error with OpenAI streaming.',\n        error: error instanceof Error ? error.message : 'Unknown error',\n        provider: 'OpenAI',\n      };\n    }\n  }\n}\n\n// Hugging Face Integration\nexport class HuggingFaceService {\n  private apiKey: string;\n  private baseUrl: string = 'https://api-inference.huggingface.co/models';\n\n  constructor(apiKey: string) {\n    this.apiKey = apiKey;\n  }\n\n  async generateResponse(\n    messages: ChatMessage[],\n    model: string = 'microsoft/DialoGPT-large'\n  ): Promise<AIResponse> {\n    try {\n      // Convert messages to a single input for most HF models\n      const input = this.formatMessagesForHF(messages);\n\n      const response = await fetch(`${this.baseUrl}/${model}`, {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${this.apiKey}`,\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          inputs: input,\n          parameters: {\n            max_length: 1000,\n            temperature: 0.7,\n            do_sample: true,\n            top_p: 0.9,\n          },\n        }),\n      });\n\n      if (!response.ok) {\n        const errorData = await response.json().catch(() => ({}));\n        throw new Error(`Hugging Face API Error: ${response.status} - ${errorData.error || 'Unknown error'}`);\n      }\n\n      const data = await response.json();\n      \n      // Handle different response formats\n      let message = '';\n      if (Array.isArray(data) && data[0]?.generated_text) {\n        message = data[0].generated_text.replace(input, '').trim();\n      } else if (data.generated_text) {\n        message = data.generated_text.replace(input, '').trim();\n      } else {\n        message = 'I received an unexpected response format.';\n      }\n\n      return {\n        message: message || 'I apologize, but I couldn\\'t generate a proper response.',\n        provider: 'Hugging Face',\n      };\n    } catch (error) {\n      console.error('Hugging Face API Error:', error);\n      return {\n        message: 'Sorry, I encountered an error with Hugging Face. Please try again.',\n        error: error instanceof Error ? error.message : 'Unknown error',\n        provider: 'Hugging Face',\n      };\n    }\n  }\n\n  // For chat-specific models like Llama, Mistral, etc.\n  async generateChatResponse(\n    messages: ChatMessage[],\n    model: string = 'meta-llama/Llama-2-7b-chat-hf'\n  ): Promise<AIResponse> {\n    try {\n      const response = await fetch(`${this.baseUrl}/${model}`, {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${this.apiKey}`,\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          inputs: {\n            messages: messages,\n          },\n          parameters: {\n            max_new_tokens: 500,\n            temperature: 0.7,\n            do_sample: true,\n          },\n        }),\n      });\n\n      if (!response.ok) {\n        throw new Error(`Hugging Face Chat API Error: ${response.status}`);\n      }\n\n      const data = await response.json();\n      \n      return {\n        message: data.choices?.[0]?.message?.content || data.generated_text || 'No response generated.',\n        provider: 'Hugging Face',\n      };\n    } catch (error) {\n      console.error('Hugging Face Chat API Error:', error);\n      return {\n        message: 'Sorry, I encountered an error with Hugging Face chat model.',\n        error: error instanceof Error ? error.message : 'Unknown error',\n        provider: 'Hugging Face',\n      };\n    }\n  }\n\n  private formatMessagesForHF(messages: ChatMessage[]): string {\n    // Format conversation for traditional text generation models\n    return messages\n      .filter(msg => msg.role !== 'system')\n      .map(msg => `${msg.role === 'user' ? 'Human' : 'Assistant'}: ${msg.content}`)\n      .join('\\n') + '\\nAssistant:';\n  }\n}\n\n// Enhanced Chatbot with multiple providers\nexport class EnhancedChatbot {\n  private openaiService?: OpenAIService;\n  private huggingfaceService?: HuggingFaceService;\n  private conversationHistory: ChatMessage[] = [];\n  private currentProvider: 'openai' | 'huggingface';\n  private systemPrompt: string;\n\n  constructor(\n    config: {\n      openaiKey?: string;\n      huggingfaceKey?: string;\n      provider?: 'openai' | 'huggingface';\n      systemPrompt?: string;\n    }\n  ) {\n    if (config.openaiKey) {\n      this.openaiService = new OpenAIService(config.openaiKey);\n    }\n    \n    if (config.huggingfaceKey) {\n      this.huggingfaceService = new HuggingFaceService(config.huggingfaceKey);\n    }\n\n    this.currentProvider = config.provider || 'openai';\n    this.systemPrompt = config.systemPrompt || \n      'You are a helpful AI assistant. Provide accurate, helpful, and engaging responses.';\n\n    // Initialize conversation with system message\n    this.conversationHistory.push({\n      role: 'system',\n      content: this.systemPrompt\n    });\n  }\n\n  async processMessage(\n    userMessage: string, \n    options: { short?: boolean } = {}\n  ): Promise<AIResponse> {\n    // Add user message to history\n    this.conversationHistory.push({\n      role: 'user',\n      content: options.short \n        ? `Please answer the following concisely, in one or two sentences at most. ${userMessage}`\n        : userMessage\n    });\n\n    // Check for predefined responses first\n    const predefinedResponse = this.checkPredefinedResponses(userMessage);\n    if (predefinedResponse) {\n      this.conversationHistory.push({\n        role: 'assistant',\n        content: predefinedResponse\n      });\n      return {\n        message: predefinedResponse,\n        provider: 'Predefined'\n      };\n    }\n\n    // Use AI service\n    let response: AIResponse;\n    \n    if (this.currentProvider === 'openai' && this.openaiService) {\n      response = await this.openaiService.generateResponse(this.conversationHistory);\n    } else if (this.currentProvider === 'huggingface' && this.huggingfaceService) {\n      response = await this.huggingfaceService.generateResponse(this.conversationHistory);\n    } else {\n      response = {\n        message: 'No AI provider configured. Please check your API keys.',\n        error: 'No provider available'\n      };\n    }\n\n    // Add assistant response to history if successful\n    if (!response.error) {\n      this.conversationHistory.push({\n        role: 'assistant',\n        content: response.message\n      });\n    }\n\n    // Keep conversation history manageable\n    this.trimConversationHistory();\n\n    return response;\n  }\n\n  switchProvider(provider: 'openai' | 'huggingface'): boolean {\n    if (provider === 'openai' && this.openaiService) {\n      this.currentProvider = 'openai';\n      return true;\n    } else if (provider === 'huggingface' && this.huggingfaceService) {\n      this.currentProvider = 'huggingface';\n      return true;\n    }\n    return false;\n  }\n\n  getCurrentProvider(): string {\n    return this.currentProvider;\n  }\n\n  private checkPredefinedResponses(message: string): string | null {\n    const lowerMessage = message.toLowerCase();\n    \n    // Quick responses for common queries\n    if (lowerMessage.match(/^(hi|hello|hey)$/)) {\n      return 'Hello! How can I help you today?';\n    }\n    \n    if (lowerMessage.includes('time')) {\n      return `The current time is ${new Date().toLocaleTimeString()}`;\n    }\n    \n    if (lowerMessage.includes('date')) {\n      return `Today's date is ${new Date().toLocaleDateString()}`;\n    }\n\n    if (lowerMessage.includes('switch to openai')) {\n      const switched = this.switchProvider('openai');\n      return switched ? 'Switched to OpenAI provider.' : 'OpenAI provider not available.';\n    }\n\n    if (lowerMessage.includes('switch to huggingface')) {\n      const switched = this.switchProvider('huggingface');\n      return switched ? 'Switched to Hugging Face provider.' : 'Hugging Face provider not available.';\n    }\n\n    return null;\n  }\n\n  private trimConversationHistory(): void {\n    // Keep last 20 messages + system message\n    if (this.conversationHistory.length > 21) {\n      this.conversationHistory = [\n        this.conversationHistory[0], // Keep system message\n        ...this.conversationHistory.slice(-20)\n      ];\n    }\n  }\n\n  clearHistory(): void {\n    this.conversationHistory = [{\n      role: 'system',\n      content: this.systemPrompt\n    }];\n  }\n\n  getConversationHistory(): ChatMessage[] {\n    return [...this.conversationHistory];\n  }\n}"],"names":[],"mappings":"AAAA,sBAAsB;;;;;;AAaf,MAAM;IACH,OAAe;IACf,UAAkB,4BAA4B;IAEtD,YAAY,MAAc,CAAE;QAC1B,IAAI,CAAC,MAAM,GAAG;IAChB;IAEA,MAAM,iBACJ,QAAuB,EACvB,QAAgB,eAAe,EACV;QACrB,IAAI;YACF,MAAM,WAAW,MAAM,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC,iBAAiB,CAAC,EAAE;gBAC/D,QAAQ;gBACR,SAAS;oBACP,gBAAgB;oBAChB,iBAAiB,CAAC,OAAO,EAAE,IAAI,CAAC,MAAM,EAAE;gBAC1C;gBACA,MAAM,KAAK,SAAS,CAAC;oBACnB,OAAO;oBACP,UAAU;oBACV,YAAY;oBACZ,aAAa;oBACb,QAAQ;gBACV;YACF;YAEA,IAAI,CAAC,SAAS,EAAE,EAAE;gBAChB,MAAM,YAAY,MAAM,SAAS,IAAI,GAAG,KAAK,CAAC,IAAM,CAAC,CAAC,CAAC;gBACvD,MAAM,eAAe,UAAU,KAAK,EAAE,WAAW,CAAC,0BAA0B,EAAE,SAAS,MAAM,EAAE;gBAC/F,QAAQ,KAAK,CAAC,CAAC,kBAAkB,EAAE,SAAS,MAAM,EAAE,EAAE;gBAEtD,IAAI,SAAS,MAAM,KAAK,KAAK;oBACzB,OAAO;wBAAE,SAAS;wBAA2D,OAAO;wBAAmB,UAAU;oBAAS;gBAC9H;gBACA,IAAI,SAAS,MAAM,KAAK,KAAK;oBACzB,OAAO;wBAAE,SAAS;wBAA4E,OAAO;wBAAuB,UAAU;oBAAS;gBACnJ;gBAEA,MAAM,IAAI,MAAM,CAAC,kBAAkB,EAAE,SAAS,MAAM,CAAC,GAAG,EAAE,cAAc;YAC1E;YAEA,MAAM,OAAO,MAAM,SAAS,IAAI;YAChC,OAAO;gBACL,SAAS,KAAK,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO;gBACxC,UAAU;YACZ;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,qBAAqB;YACnC,OAAO;gBACL,SAAS;gBACT,OAAO,iBAAiB,QAAQ,MAAM,OAAO,GAAG;gBAChD,UAAU;YACZ;QACF;IACF;IAEA,qCAAqC;IACrC,MAAM,uBACJ,QAAuB,EACvB,OAAgC,EAChC,QAAgB,eAAe,EACV;QACrB,IAAI;YACF,MAAM,WAAW,MAAM,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC,iBAAiB,CAAC,EAAE;gBAC/D,QAAQ;gBACR,SAAS;oBACP,gBAAgB;oBAChB,iBAAiB,CAAC,OAAO,EAAE,IAAI,CAAC,MAAM,EAAE;gBAC1C;gBACA,MAAM,KAAK,SAAS,CAAC;oBACnB,OAAO;oBACP,UAAU;oBACV,YAAY;oBACZ,aAAa;oBACb,QAAQ;gBACV;YACF;YAEA,IAAI,CAAC,SAAS,EAAE,EAAE;gBAChB,MAAM,IAAI,MAAM,CAAC,kBAAkB,EAAE,SAAS,MAAM,EAAE;YACxD;YAEA,MAAM,SAAS,SAAS,IAAI,EAAE;YAC9B,IAAI,CAAC,QAAQ,MAAM,IAAI,MAAM;YAE7B,IAAI,cAAc;YAElB,MAAO,KAAM;gBACX,MAAM,EAAE,IAAI,EAAE,KAAK,EAAE,GAAG,MAAM,OAAO,IAAI;gBACzC,IAAI,MAAM;gBAEV,MAAM,QAAQ,IAAI,cAAc,MAAM,CAAC;gBACvC,MAAM,QAAQ,MAAM,KAAK,CAAC,MAAM,MAAM,CAAC,CAAA,OAAQ,KAAK,IAAI;gBAExD,KAAK,MAAM,QAAQ,MAAO;oBACxB,IAAI,KAAK,UAAU,CAAC,WAAW;wBAC7B,MAAM,OAAO,KAAK,KAAK,CAAC;wBACxB,IAAI,SAAS,UAAU;wBAEvB,IAAI;4BACF,MAAM,SAAS,KAAK,KAAK,CAAC;4BAC1B,MAAM,UAAU,OAAO,OAAO,CAAC,EAAE,EAAE,OAAO;4BAC1C,IAAI,SAAS;gCACX,eAAe;gCACf,QAAQ;4BACV;wBACF,EAAE,OAAO,GAAG;wBACV,oBAAoB;wBACtB;oBACF;gBACF;YACF;YAEA,OAAO;gBACL,SAAS;gBACT,UAAU;YACZ;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,2BAA2B;YACzC,OAAO;gBACL,SAAS;gBACT,OAAO,iBAAiB,QAAQ,MAAM,OAAO,GAAG;gBAChD,UAAU;YACZ;QACF;IACF;AACF;AAGO,MAAM;IACH,OAAe;IACf,UAAkB,8CAA8C;IAExE,YAAY,MAAc,CAAE;QAC1B,IAAI,CAAC,MAAM,GAAG;IAChB;IAEA,MAAM,iBACJ,QAAuB,EACvB,QAAgB,0BAA0B,EACrB;QACrB,IAAI;YACF,wDAAwD;YACxD,MAAM,QAAQ,IAAI,CAAC,mBAAmB,CAAC;YAEvC,MAAM,WAAW,MAAM,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,EAAE,OAAO,EAAE;gBACvD,QAAQ;gBACR,SAAS;oBACP,iBAAiB,CAAC,OAAO,EAAE,IAAI,CAAC,MAAM,EAAE;oBACxC,gBAAgB;gBAClB;gBACA,MAAM,KAAK,SAAS,CAAC;oBACnB,QAAQ;oBACR,YAAY;wBACV,YAAY;wBACZ,aAAa;wBACb,WAAW;wBACX,OAAO;oBACT;gBACF;YACF;YAEA,IAAI,CAAC,SAAS,EAAE,EAAE;gBAChB,MAAM,YAAY,MAAM,SAAS,IAAI,GAAG,KAAK,CAAC,IAAM,CAAC,CAAC,CAAC;gBACvD,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,SAAS,MAAM,CAAC,GAAG,EAAE,UAAU,KAAK,IAAI,iBAAiB;YACtG;YAEA,MAAM,OAAO,MAAM,SAAS,IAAI;YAEhC,oCAAoC;YACpC,IAAI,UAAU;YACd,IAAI,MAAM,OAAO,CAAC,SAAS,IAAI,CAAC,EAAE,EAAE,gBAAgB;gBAClD,UAAU,IAAI,CAAC,EAAE,CAAC,cAAc,CAAC,OAAO,CAAC,OAAO,IAAI,IAAI;YAC1D,OAAO,IAAI,KAAK,cAAc,EAAE;gBAC9B,UAAU,KAAK,cAAc,CAAC,OAAO,CAAC,OAAO,IAAI,IAAI;YACvD,OAAO;gBACL,UAAU;YACZ;YAEA,OAAO;gBACL,SAAS,WAAW;gBACpB,UAAU;YACZ;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,2BAA2B;YACzC,OAAO;gBACL,SAAS;gBACT,OAAO,iBAAiB,QAAQ,MAAM,OAAO,GAAG;gBAChD,UAAU;YACZ;QACF;IACF;IAEA,qDAAqD;IACrD,MAAM,qBACJ,QAAuB,EACvB,QAAgB,+BAA+B,EAC1B;QACrB,IAAI;YACF,MAAM,WAAW,MAAM,MAAM,GAAG,IAAI,CAAC,OAAO,CAAC,CAAC,EAAE,OAAO,EAAE;gBACvD,QAAQ;gBACR,SAAS;oBACP,iBAAiB,CAAC,OAAO,EAAE,IAAI,CAAC,MAAM,EAAE;oBACxC,gBAAgB;gBAClB;gBACA,MAAM,KAAK,SAAS,CAAC;oBACnB,QAAQ;wBACN,UAAU;oBACZ;oBACA,YAAY;wBACV,gBAAgB;wBAChB,aAAa;wBACb,WAAW;oBACb;gBACF;YACF;YAEA,IAAI,CAAC,SAAS,EAAE,EAAE;gBAChB,MAAM,IAAI,MAAM,CAAC,6BAA6B,EAAE,SAAS,MAAM,EAAE;YACnE;YAEA,MAAM,OAAO,MAAM,SAAS,IAAI;YAEhC,OAAO;gBACL,SAAS,KAAK,OAAO,EAAE,CAAC,EAAE,EAAE,SAAS,WAAW,KAAK,cAAc,IAAI;gBACvE,UAAU;YACZ;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,gCAAgC;YAC9C,OAAO;gBACL,SAAS;gBACT,OAAO,iBAAiB,QAAQ,MAAM,OAAO,GAAG;gBAChD,UAAU;YACZ;QACF;IACF;IAEQ,oBAAoB,QAAuB,EAAU;QAC3D,6DAA6D;QAC7D,OAAO,SACJ,MAAM,CAAC,CAAA,MAAO,IAAI,IAAI,KAAK,UAC3B,GAAG,CAAC,CAAA,MAAO,GAAG,IAAI,IAAI,KAAK,SAAS,UAAU,YAAY,EAAE,EAAE,IAAI,OAAO,EAAE,EAC3E,IAAI,CAAC,QAAQ;IAClB;AACF;AAGO,MAAM;IACH,cAA8B;IAC9B,mBAAwC;IACxC,sBAAqC,EAAE,CAAC;IACxC,gBAA0C;IAC1C,aAAqB;IAE7B,YACE,MAKC,CACD;QACA,IAAI,OAAO,SAAS,EAAE;YACpB,IAAI,CAAC,aAAa,GAAG,IAAI,cAAc,OAAO,SAAS;QACzD;QAEA,IAAI,OAAO,cAAc,EAAE;YACzB,IAAI,CAAC,kBAAkB,GAAG,IAAI,mBAAmB,OAAO,cAAc;QACxE;QAEA,IAAI,CAAC,eAAe,GAAG,OAAO,QAAQ,IAAI;QAC1C,IAAI,CAAC,YAAY,GAAG,OAAO,YAAY,IACrC;QAEF,8CAA8C;QAC9C,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC;YAC5B,MAAM;YACN,SAAS,IAAI,CAAC,YAAY;QAC5B;IACF;IAEA,MAAM,eACJ,WAAmB,EACnB,UAA+B,CAAC,CAAC,EACZ;QACrB,8BAA8B;QAC9B,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC;YAC5B,MAAM;YACN,SAAS,QAAQ,KAAK,GAClB,CAAC,wEAAwE,EAAE,aAAa,GACxF;QACN;QAEA,uCAAuC;QACvC,MAAM,qBAAqB,IAAI,CAAC,wBAAwB,CAAC;QACzD,IAAI,oBAAoB;YACtB,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC;gBAC5B,MAAM;gBACN,SAAS;YACX;YACA,OAAO;gBACL,SAAS;gBACT,UAAU;YACZ;QACF;QAEA,iBAAiB;QACjB,IAAI;QAEJ,IAAI,IAAI,CAAC,eAAe,KAAK,YAAY,IAAI,CAAC,aAAa,EAAE;YAC3D,WAAW,MAAM,IAAI,CAAC,aAAa,CAAC,gBAAgB,CAAC,IAAI,CAAC,mBAAmB;QAC/E,OAAO,IAAI,IAAI,CAAC,eAAe,KAAK,iBAAiB,IAAI,CAAC,kBAAkB,EAAE;YAC5E,WAAW,MAAM,IAAI,CAAC,kBAAkB,CAAC,gBAAgB,CAAC,IAAI,CAAC,mBAAmB;QACpF,OAAO;YACL,WAAW;gBACT,SAAS;gBACT,OAAO;YACT;QACF;QAEA,kDAAkD;QAClD,IAAI,CAAC,SAAS,KAAK,EAAE;YACnB,IAAI,CAAC,mBAAmB,CAAC,IAAI,CAAC;gBAC5B,MAAM;gBACN,SAAS,SAAS,OAAO;YAC3B;QACF;QAEA,uCAAuC;QACvC,IAAI,CAAC,uBAAuB;QAE5B,OAAO;IACT;IAEA,eAAe,QAAkC,EAAW;QAC1D,IAAI,aAAa,YAAY,IAAI,CAAC,aAAa,EAAE;YAC/C,IAAI,CAAC,eAAe,GAAG;YACvB,OAAO;QACT,OAAO,IAAI,aAAa,iBAAiB,IAAI,CAAC,kBAAkB,EAAE;YAChE,IAAI,CAAC,eAAe,GAAG;YACvB,OAAO;QACT;QACA,OAAO;IACT;IAEA,qBAA6B;QAC3B,OAAO,IAAI,CAAC,eAAe;IAC7B;IAEQ,yBAAyB,OAAe,EAAiB;QAC/D,MAAM,eAAe,QAAQ,WAAW;QAExC,qCAAqC;QACrC,IAAI,aAAa,KAAK,CAAC,qBAAqB;YAC1C,OAAO;QACT;QAEA,IAAI,aAAa,QAAQ,CAAC,SAAS;YACjC,OAAO,CAAC,oBAAoB,EAAE,IAAI,OAAO,kBAAkB,IAAI;QACjE;QAEA,IAAI,aAAa,QAAQ,CAAC,SAAS;YACjC,OAAO,CAAC,gBAAgB,EAAE,IAAI,OAAO,kBAAkB,IAAI;QAC7D;QAEA,IAAI,aAAa,QAAQ,CAAC,qBAAqB;YAC7C,MAAM,WAAW,IAAI,CAAC,cAAc,CAAC;YACrC,OAAO,WAAW,iCAAiC;QACrD;QAEA,IAAI,aAAa,QAAQ,CAAC,0BAA0B;YAClD,MAAM,WAAW,IAAI,CAAC,cAAc,CAAC;YACrC,OAAO,WAAW,uCAAuC;QAC3D;QAEA,OAAO;IACT;IAEQ,0BAAgC;QACtC,yCAAyC;QACzC,IAAI,IAAI,CAAC,mBAAmB,CAAC,MAAM,GAAG,IAAI;YACxC,IAAI,CAAC,mBAAmB,GAAG;gBACzB,IAAI,CAAC,mBAAmB,CAAC,EAAE;mBACxB,IAAI,CAAC,mBAAmB,CAAC,KAAK,CAAC,CAAC;aACpC;QACH;IACF;IAEA,eAAqB;QACnB,IAAI,CAAC,mBAAmB,GAAG;YAAC;gBAC1B,MAAM;gBACN,SAAS,IAAI,CAAC,YAAY;YAC5B;SAAE;IACJ;IAEA,yBAAwC;QACtC,OAAO;eAAI,IAAI,CAAC,mBAAmB;SAAC;IACtC;AACF","debugId":null}},
    {"offset": {"line": 402, "column": 0}, "map": {"version":3,"sources":["file:///Users/plana/Desktop/test/src/app/api/motivation/route.ts"],"sourcesContent":["import { NextRequest, NextResponse } from 'next/server';\nimport { EnhancedChatbot } from '@/lib/ai-provider';\n\nfunction getMotivationPrompt(type: 'positive' | 'tough'): string {\n    if (type === 'tough') {\n        return \"You are a tough-love motivational coach. Your goal is to give a user a short, powerful, no-excuses message to get them motivated. It should be direct, blunt, and inspiring. Focus on action and overcoming self-doubt. The user needs a kick in the pants. Generate a single motivational phrase or a 2-3 sentence paragraph.\";\n    }\n    // Default to positive\n    return \"You are a kind and compassionate motivational coach. Your goal is to give a user a short, powerful, and uplifting message. It should be full of encouragement, self-love, and belief in their potential. The user needs gentle and positive reinforcement. Generate a single motivational phrase or a 2-3 sentence paragraph.\";\n}\n\n\nexport async function POST(request: NextRequest) {\n  try {\n    const body = await request.json();\n    const { type } = body;\n\n    if (type !== 'positive' && type !== 'tough') {\n      return NextResponse.json({ error: 'Invalid motivation type specified' }, { status: 400 });\n    }\n\n    const systemPrompt = getMotivationPrompt(type);\n    \n    const chatbot = new EnhancedChatbot({\n      openaiKey: process.env.OPENAI_API_KEY || '',\n      systemPrompt: systemPrompt,\n    });\n      \n    const response = await chatbot.processMessage(\"Give me a motivational message.\");\n\n    if (response.error) {\n      console.error('Motivation API Error from AI Provider:', response.error);\n      return NextResponse.json({ error: response.message || 'Internal server error' }, { status: 500 });\n    }\n    \n    return NextResponse.json({ \n      message: response.message,\n      timestamp: new Date().toISOString()\n    });\n\n  } catch (error) {\n    console.error('Motivation API Error:', error);\n    return NextResponse.json(\n      { error: 'Internal server error' }, \n      { status: 500 }\n    );\n  }\n} "],"names":[],"mappings":";;;AAAA;AACA;;;AAEA,SAAS,oBAAoB,IAA0B;IACnD,IAAI,SAAS,SAAS;QAClB,OAAO;IACX;IACA,sBAAsB;IACtB,OAAO;AACX;AAGO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,OAAO,MAAM,QAAQ,IAAI;QAC/B,MAAM,EAAE,IAAI,EAAE,GAAG;QAEjB,IAAI,SAAS,cAAc,SAAS,SAAS;YAC3C,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;gBAAE,OAAO;YAAoC,GAAG;gBAAE,QAAQ;YAAI;QACzF;QAEA,MAAM,eAAe,oBAAoB;QAEzC,MAAM,UAAU,IAAI,8HAAA,CAAA,kBAAe,CAAC;YAClC,WAAW,QAAQ,GAAG,CAAC,cAAc,IAAI;YACzC,cAAc;QAChB;QAEA,MAAM,WAAW,MAAM,QAAQ,cAAc,CAAC;QAE9C,IAAI,SAAS,KAAK,EAAE;YAClB,QAAQ,KAAK,CAAC,0CAA0C,SAAS,KAAK;YACtE,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;gBAAE,OAAO,SAAS,OAAO,IAAI;YAAwB,GAAG;gBAAE,QAAQ;YAAI;QACjG;QAEA,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;YACvB,SAAS,SAAS,OAAO;YACzB,WAAW,IAAI,OAAO,WAAW;QACnC;IAEF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,yBAAyB;QACvC,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAAwB,GACjC;YAAE,QAAQ;QAAI;IAElB;AACF","debugId":null}}]
}