{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 6, "column": 0}, "map": {"version":3,"sources":[],"names":[],"mappings":"","debugId":null}},
    {"offset": {"line": 60, "column": 0}, "map": {"version":3,"sources":["file:///Users/plana/Desktop/test/src/lib/tokenizer.ts"],"sourcesContent":["// Types and interfaces\nexport interface Token {\n  id: number;\n  text: string;\n  type: 'word' | 'punctuation' | 'special' | 'number';\n}\n\nexport interface Message {\n  id: string;\n  text: string;\n  tokens: Token[];\n  timestamp: Date;\n  sender: 'user' | 'bot';\n}\n\nexport interface TokenizerConfig {\n  maxVocabSize: number;\n  specialTokens: string[];\n  caseSensitive: boolean;\n}\n\n// Fixed Tokenizer class\nexport class Tokenizer {\n  private vocabulary: Map<string, number> = new Map();\n  private reverseVocab: Map<number, string> = new Map();\n  private tokenId: number = 0;\n  private config: TokenizerConfig;\n\n  constructor(config: Partial<TokenizerConfig> = {}) {\n    this.config = {\n      maxVocabSize: 10000,\n      specialTokens: ['<pad>', '<unk>', '<bos>', '<eos>', '<user>', '<bot>', '<start>', '<end>'],\n      caseSensitive: false,\n      ...config\n    };\n    \n    // Initialize with special tokens\n    this.initializeSpecialTokens();\n  }\n\n  private initializeSpecialTokens(): void {\n    this.config.specialTokens.forEach(token => {\n      this.addToken(token, 'special');\n    });\n  }\n\n  public addToken(text: string, type: Token['type'] = 'word'): number {\n    const normalizedText = this.config.caseSensitive ? text : text.toLowerCase();\n    \n    if (this.vocabulary.has(normalizedText)) {\n      return this.vocabulary.get(normalizedText)!;\n    }\n\n    // Check if we've reached max vocab size (except for special tokens)\n    if (this.vocabulary.size >= this.config.maxVocabSize && type !== 'special') {\n      const unkId = this.vocabulary.get('<unk>');\n      if (unkId !== undefined) {\n        return unkId;\n      }\n    }\n\n    const id = this.tokenId++;\n    this.vocabulary.set(normalizedText, id);\n    this.reverseVocab.set(id, normalizedText);\n    return id;\n  }\n\n  public tokenize(text: string): Token[] {\n    if (!text || typeof text !== 'string') {\n      return [];\n    }\n\n    const tokens: Token[] = [];\n    \n    // Improved tokenization - handle punctuation better\n    const words = text\n      .replace(/([.!?;,:])/g, ' $1 ') // Add spaces around punctuation\n      .split(/\\s+/)\n      .filter(word => word.length > 0);\n    \n    words.forEach(word => {\n      const normalizedWord = this.config.caseSensitive ? word : word.toLowerCase();\n      const type = this.getTokenType(word);\n      let tokenId = this.vocabulary.get(normalizedWord);\n      \n      if (tokenId === undefined) {\n        tokenId = this.addToken(normalizedWord, type);\n      }\n      \n      tokens.push({\n        id: tokenId,\n        text: word,\n        type: type\n      });\n    });\n    \n    return tokens;\n  }\n\n  private getTokenType(text: string): Token['type'] {\n    const normalizedText = this.config.caseSensitive ? text : text.toLowerCase();\n    \n    if (this.config.specialTokens.includes(normalizedText)) return 'special';\n    if (/^\\d+\\.?\\d*$/.test(text)) return 'number'; // Handles integers and decimals\n    if (/^[^\\w\\s]+$/.test(text)) return 'punctuation'; // Handles all punctuation\n    return 'word';\n  }\n\n  public encode(text: string): number[] {\n    const tokens = this.tokenize(text);\n    return tokens.map(token => token.id);\n  }\n\n  public decode(ids: number[]): string {\n    return ids\n      .map(id => this.reverseVocab.get(id) || '<unk>')\n      .join(' ')\n      .replace(/\\s+([.!?;,:)])/g, '$1') // Remove spaces before punctuation\n      .replace(/\\(\\s+/g, '('); // Remove spaces after opening parentheses\n  }\n\n  public detokenize(tokens: Token[]): string {\n    return tokens\n      .map(token => token.text)\n      .join(' ')\n      .replace(/\\s+([.!?;,:)])/g, '$1') // Clean up punctuation spacing\n      .replace(/\\(\\s+/g, '(');\n  }\n\n  public getVocabSize(): number {\n    return this.vocabulary.size;\n  }\n\n  public getVocabulary(): Map<string, number> {\n    return new Map(this.vocabulary);\n  }\n\n  public getTokenById(id: number): string | undefined {\n    return this.reverseVocab.get(id);\n  }\n\n  public hasToken(text: string): boolean {\n    const normalizedText = this.config.caseSensitive ? text : text.toLowerCase();\n    return this.vocabulary.has(normalizedText);\n  }\n\n  public getTokenId(text: string): number | undefined {\n    const normalizedText = this.config.caseSensitive ? text : text.toLowerCase();\n    return this.vocabulary.get(normalizedText);\n  }\n}\n\n// Simple AI Response Generator\nexport class AIResponseGenerator {\n  private responses: Map<string, string[]> = new Map([\n    ['greeting', ['Hello! How can I help you today?', 'Hi there! What can I do for you?', 'Greetings! How may I assist you?']],\n    ['question', ['That\\'s an interesting question!', 'Let me think about that...', 'I\\'d be happy to help with that.']],\n    ['default', ['I understand.', 'That\\'s interesting.', 'Tell me more about that.', 'I see what you mean.']],\n    ['goodbye', ['Goodbye! Have a great day!', 'See you later!', 'Until next time!']]\n  ]);\n\n  generateResponse(userMessage: string, tokens: Token[]): string {\n    const lowerMessage = userMessage.toLowerCase();\n    \n    // Simple rule-based responses\n    if (lowerMessage.includes('hello') || lowerMessage.includes('hi') || lowerMessage.includes('hey')) {\n      return this.getRandomResponse('greeting');\n    }\n    \n    if (lowerMessage.includes('?')) {\n      return this.getRandomResponse('question');\n    }\n    \n    if (lowerMessage.includes('bye') || lowerMessage.includes('goodbye')) {\n      return this.getRandomResponse('goodbye');\n    }\n    \n    // Echo back with token info\n    const tokenCount = tokens.length;\n    const uniqueTokens = new Set(tokens.map(t => t.text.toLowerCase())).size;\n    const tokenTypes = tokens.reduce((acc, token) => {\n      acc[token.type] = (acc[token.type] || 0) + 1;\n      return acc;\n    }, {} as Record<string, number>);\n    \n    return `${this.getRandomResponse('default')} Your message had ${tokenCount} tokens (${uniqueTokens} unique). Token breakdown: ${Object.entries(tokenTypes).map(([type, count]) => `${count} ${type}`).join(', ')}.`;\n  }\n\n  private getRandomResponse(category: string): string {\n    const responses = this.responses.get(category) || this.responses.get('default')!;\n    return responses[Math.floor(Math.random() * responses.length)];\n  }\n}\n\n// Main Chatbot class\nexport class AIChatbot {\n  private tokenizer: Tokenizer;\n  private responseGenerator: AIResponseGenerator;\n  private messages: Message[] = [];\n  private messageIdCounter: number = 0;\n\n  constructor(tokenizerConfig?: Partial<TokenizerConfig>) {\n    this.tokenizer = new Tokenizer(tokenizerConfig);\n    this.responseGenerator = new AIResponseGenerator();\n    \n    // Pre-populate with common words\n    this.initializeCommonVocabulary();\n  }\n\n  private initializeCommonVocabulary(): void {\n    const commonWords = [\n      'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', 'of', 'with',\n      'by', 'is', 'are', 'was', 'were', 'be', 'been', 'have', 'has', 'had', 'do', 'does',\n      'did', 'will', 'would', 'could', 'should', 'can', 'may', 'might', 'must', 'shall',\n      'this', 'that', 'these', 'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they',\n      'me', 'him', 'her', 'us', 'them', 'my', 'your', 'his', 'her', 'its', 'our', 'their',\n      'what', 'when', 'where', 'why', 'how', 'who', 'which', 'hello', 'hi', 'bye', 'goodbye',\n      'please', 'thank', 'thanks', 'yes', 'no', 'ok', 'okay'\n    ];\n    \n    commonWords.forEach(word => this.tokenizer.addToken(word, 'word'));\n  }\n\n  public async processMessage(userInput: string): Promise<Message> {\n    // Tokenize user input\n    const userTokens = this.tokenizer.tokenize(userInput);\n    \n    // Create user message\n    const userMessage: Message = {\n      id: `msg_${this.messageIdCounter++}`,\n      text: userInput,\n      tokens: userTokens,\n      timestamp: new Date(),\n      sender: 'user'\n    };\n    \n    this.messages.push(userMessage);\n    \n    // Generate bot response\n    const botResponseText = this.responseGenerator.generateResponse(userInput, userTokens);\n    const botTokens = this.tokenizer.tokenize(botResponseText);\n    \n    const botMessage: Message = {\n      id: `msg_${this.messageIdCounter++}`,\n      text: botResponseText,\n      tokens: botTokens,\n      timestamp: new Date(),\n      sender: 'bot'\n    };\n    \n    this.messages.push(botMessage);\n    \n    return botMessage;\n  }\n\n  public getMessages(): Message[] {\n    return [...this.messages];\n  }\n\n  public getTokenizer(): Tokenizer {\n    return this.tokenizer;\n  }\n\n  public getVocabularyStats(): {\n    size: number;\n    maxSize: number;\n    specialTokens: number;\n    wordTokens: number;\n    punctuationTokens: number;\n    numberTokens: number;\n  } {\n    const allTokens = this.messages.flatMap(msg => msg.tokens);\n    const tokenTypes = allTokens.reduce((acc, token) => {\n      acc[token.type] = (acc[token.type] || 0) + 1;\n      return acc;\n    }, {} as Record<string, number>);\n\n    return {\n      size: this.tokenizer.getVocabSize(),\n      maxSize: this.tokenizer['config'].maxVocabSize,\n      specialTokens: tokenTypes.special || 0,\n      wordTokens: tokenTypes.word || 0,\n      punctuationTokens: tokenTypes.punctuation || 0,\n      numberTokens: tokenTypes.number || 0\n    };\n  }\n\n  public exportConversation(): string {\n    return JSON.stringify(this.messages, null, 2);\n  }\n\n  public clearConversation(): void {\n    this.messages = [];\n    this.messageIdCounter = 0;\n  }\n}\n\n// Usage example and testing function\nexport async function runChatbot(): Promise<AIChatbot> {\n  const chatbot = new AIChatbot({\n    maxVocabSize: 5000,\n    caseSensitive: false\n  });\n\n  console.log('AI Chatbot initialized!');\n  console.log('Vocabulary size:', chatbot.getVocabularyStats().size);\n  \n  // Simulate conversation\n  const testMessages = [\n    \"Hello there!\",\n    \"How are you doing today?\",\n    \"Can you help me with programming?\",\n    \"What's 2 + 2?\",\n    \"Thanks for your help. Goodbye!\"\n  ];\n\n  for (const message of testMessages) {\n    console.log(`\\nUser: ${message}`);\n    const response = await chatbot.processMessage(message);\n    console.log(`Bot: ${response.text}`);\n    console.log(`Tokens: [${response.tokens.map(t => `${t.text}(${t.type})`).join(', ')}]`);\n  }\n\n  console.log('\\n--- Conversation Stats ---');\n  const stats = chatbot.getVocabularyStats();\n  console.log(`Total vocabulary: ${stats.size}/${stats.maxSize}`);\n  console.log(`Word tokens: ${stats.wordTokens}`);\n  console.log(`Special tokens: ${stats.specialTokens}`);\n  console.log(`Punctuation tokens: ${stats.punctuationTokens}`);\n  console.log(`Number tokens: ${stats.numberTokens}`);\n\n  return chatbot;\n}\n\n// Create a default tokenizer instance for standalone use\nexport const defaultTokenizer = new Tokenizer();\n\n// Export convenience function for quick tokenization\nexport function tokenize(text: string): Token[] {\n  return defaultTokenizer.tokenize(text);\n}\n\n// For Node.js execution\nif (typeof require !== 'undefined' && require.main === module) {\n  runChatbot().catch(console.error);\n}"],"names":[],"mappings":"AAAA,uBAAuB;;;;;;;;;AAsBhB,MAAM;IACH,aAAkC,IAAI,MAAM;IAC5C,eAAoC,IAAI,MAAM;IAC9C,UAAkB,EAAE;IACpB,OAAwB;IAEhC,YAAY,SAAmC,CAAC,CAAC,CAAE;QACjD,IAAI,CAAC,MAAM,GAAG;YACZ,cAAc;YACd,eAAe;gBAAC;gBAAS;gBAAS;gBAAS;gBAAS;gBAAU;gBAAS;gBAAW;aAAQ;YAC1F,eAAe;YACf,GAAG,MAAM;QACX;QAEA,iCAAiC;QACjC,IAAI,CAAC,uBAAuB;IAC9B;IAEQ,0BAAgC;QACtC,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,OAAO,CAAC,CAAA;YAChC,IAAI,CAAC,QAAQ,CAAC,OAAO;QACvB;IACF;IAEO,SAAS,IAAY,EAAE,OAAsB,MAAM,EAAU;QAClE,MAAM,iBAAiB,IAAI,CAAC,MAAM,CAAC,aAAa,GAAG,OAAO,KAAK,WAAW;QAE1E,IAAI,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,iBAAiB;YACvC,OAAO,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC;QAC7B;QAEA,oEAAoE;QACpE,IAAI,IAAI,CAAC,UAAU,CAAC,IAAI,IAAI,IAAI,CAAC,MAAM,CAAC,YAAY,IAAI,SAAS,WAAW;YAC1E,MAAM,QAAQ,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC;YAClC,IAAI,UAAU,WAAW;gBACvB,OAAO;YACT;QACF;QAEA,MAAM,KAAK,IAAI,CAAC,OAAO;QACvB,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC,gBAAgB;QACpC,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,IAAI;QAC1B,OAAO;IACT;IAEO,SAAS,IAAY,EAAW;QACrC,IAAI,CAAC,QAAQ,OAAO,SAAS,UAAU;YACrC,OAAO,EAAE;QACX;QAEA,MAAM,SAAkB,EAAE;QAE1B,oDAAoD;QACpD,MAAM,QAAQ,KACX,OAAO,CAAC,eAAe,QAAQ,gCAAgC;SAC/D,KAAK,CAAC,OACN,MAAM,CAAC,CAAA,OAAQ,KAAK,MAAM,GAAG;QAEhC,MAAM,OAAO,CAAC,CAAA;YACZ,MAAM,iBAAiB,IAAI,CAAC,MAAM,CAAC,aAAa,GAAG,OAAO,KAAK,WAAW;YAC1E,MAAM,OAAO,IAAI,CAAC,YAAY,CAAC;YAC/B,IAAI,UAAU,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC;YAElC,IAAI,YAAY,WAAW;gBACzB,UAAU,IAAI,CAAC,QAAQ,CAAC,gBAAgB;YAC1C;YAEA,OAAO,IAAI,CAAC;gBACV,IAAI;gBACJ,MAAM;gBACN,MAAM;YACR;QACF;QAEA,OAAO;IACT;IAEQ,aAAa,IAAY,EAAiB;QAChD,MAAM,iBAAiB,IAAI,CAAC,MAAM,CAAC,aAAa,GAAG,OAAO,KAAK,WAAW;QAE1E,IAAI,IAAI,CAAC,MAAM,CAAC,aAAa,CAAC,QAAQ,CAAC,iBAAiB,OAAO;QAC/D,IAAI,cAAc,IAAI,CAAC,OAAO,OAAO,UAAU,gCAAgC;QAC/E,IAAI,aAAa,IAAI,CAAC,OAAO,OAAO,eAAe,0BAA0B;QAC7E,OAAO;IACT;IAEO,OAAO,IAAY,EAAY;QACpC,MAAM,SAAS,IAAI,CAAC,QAAQ,CAAC;QAC7B,OAAO,OAAO,GAAG,CAAC,CAAA,QAAS,MAAM,EAAE;IACrC;IAEO,OAAO,GAAa,EAAU;QACnC,OAAO,IACJ,GAAG,CAAC,CAAA,KAAM,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC,OAAO,SACvC,IAAI,CAAC,KACL,OAAO,CAAC,mBAAmB,MAAM,mCAAmC;SACpE,OAAO,CAAC,UAAU,MAAM,0CAA0C;IACvE;IAEO,WAAW,MAAe,EAAU;QACzC,OAAO,OACJ,GAAG,CAAC,CAAA,QAAS,MAAM,IAAI,EACvB,IAAI,CAAC,KACL,OAAO,CAAC,mBAAmB,MAAM,+BAA+B;SAChE,OAAO,CAAC,UAAU;IACvB;IAEO,eAAuB;QAC5B,OAAO,IAAI,CAAC,UAAU,CAAC,IAAI;IAC7B;IAEO,gBAAqC;QAC1C,OAAO,IAAI,IAAI,IAAI,CAAC,UAAU;IAChC;IAEO,aAAa,EAAU,EAAsB;QAClD,OAAO,IAAI,CAAC,YAAY,CAAC,GAAG,CAAC;IAC/B;IAEO,SAAS,IAAY,EAAW;QACrC,MAAM,iBAAiB,IAAI,CAAC,MAAM,CAAC,aAAa,GAAG,OAAO,KAAK,WAAW;QAC1E,OAAO,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC;IAC7B;IAEO,WAAW,IAAY,EAAsB;QAClD,MAAM,iBAAiB,IAAI,CAAC,MAAM,CAAC,aAAa,GAAG,OAAO,KAAK,WAAW;QAC1E,OAAO,IAAI,CAAC,UAAU,CAAC,GAAG,CAAC;IAC7B;AACF;AAGO,MAAM;IACH,YAAmC,IAAI,IAAI;QACjD;YAAC;YAAY;gBAAC;gBAAoC;gBAAoC;aAAmC;SAAC;QAC1H;YAAC;YAAY;gBAAC;gBAAoC;gBAA8B;aAAmC;SAAC;QACpH;YAAC;YAAW;gBAAC;gBAAiB;gBAAwB;gBAA4B;aAAuB;SAAC;QAC1G;YAAC;YAAW;gBAAC;gBAA8B;gBAAkB;aAAmB;SAAC;KAClF,EAAE;IAEH,iBAAiB,WAAmB,EAAE,MAAe,EAAU;QAC7D,MAAM,eAAe,YAAY,WAAW;QAE5C,8BAA8B;QAC9B,IAAI,aAAa,QAAQ,CAAC,YAAY,aAAa,QAAQ,CAAC,SAAS,aAAa,QAAQ,CAAC,QAAQ;YACjG,OAAO,IAAI,CAAC,iBAAiB,CAAC;QAChC;QAEA,IAAI,aAAa,QAAQ,CAAC,MAAM;YAC9B,OAAO,IAAI,CAAC,iBAAiB,CAAC;QAChC;QAEA,IAAI,aAAa,QAAQ,CAAC,UAAU,aAAa,QAAQ,CAAC,YAAY;YACpE,OAAO,IAAI,CAAC,iBAAiB,CAAC;QAChC;QAEA,4BAA4B;QAC5B,MAAM,aAAa,OAAO,MAAM;QAChC,MAAM,eAAe,IAAI,IAAI,OAAO,GAAG,CAAC,CAAA,IAAK,EAAE,IAAI,CAAC,WAAW,KAAK,IAAI;QACxE,MAAM,aAAa,OAAO,MAAM,CAAC,CAAC,KAAK;YACrC,GAAG,CAAC,MAAM,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,IAAI;YAC3C,OAAO;QACT,GAAG,CAAC;QAEJ,OAAO,GAAG,IAAI,CAAC,iBAAiB,CAAC,WAAW,kBAAkB,EAAE,WAAW,SAAS,EAAE,aAAa,2BAA2B,EAAE,OAAO,OAAO,CAAC,YAAY,GAAG,CAAC,CAAC,CAAC,MAAM,MAAM,GAAK,GAAG,MAAM,CAAC,EAAE,MAAM,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;IACrN;IAEQ,kBAAkB,QAAgB,EAAU;QAClD,MAAM,YAAY,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC,aAAa,IAAI,CAAC,SAAS,CAAC,GAAG,CAAC;QACrE,OAAO,SAAS,CAAC,KAAK,KAAK,CAAC,KAAK,MAAM,KAAK,UAAU,MAAM,EAAE;IAChE;AACF;AAGO,MAAM;IACH,UAAqB;IACrB,kBAAuC;IACvC,WAAsB,EAAE,CAAC;IACzB,mBAA2B,EAAE;IAErC,YAAY,eAA0C,CAAE;QACtD,IAAI,CAAC,SAAS,GAAG,IAAI,UAAU;QAC/B,IAAI,CAAC,iBAAiB,GAAG,IAAI;QAE7B,iCAAiC;QACjC,IAAI,CAAC,0BAA0B;IACjC;IAEQ,6BAAmC;QACzC,MAAM,cAAc;YAClB;YAAO;YAAK;YAAM;YAAO;YAAM;YAAO;YAAM;YAAM;YAAM;YAAM;YAAO;YAAM;YAC3E;YAAM;YAAM;YAAO;YAAO;YAAQ;YAAM;YAAQ;YAAQ;YAAO;YAAO;YAAM;YAC5E;YAAO;YAAQ;YAAS;YAAS;YAAU;YAAO;YAAO;YAAS;YAAQ;YAC1E;YAAQ;YAAQ;YAAS;YAAS;YAAK;YAAO;YAAM;YAAO;YAAM;YAAM;YACvE;YAAM;YAAO;YAAO;YAAM;YAAQ;YAAM;YAAQ;YAAO;YAAO;YAAO;YAAO;YAC5E;YAAQ;YAAQ;YAAS;YAAO;YAAO;YAAO;YAAS;YAAS;YAAM;YAAO;YAC7E;YAAU;YAAS;YAAU;YAAO;YAAM;YAAM;SACjD;QAED,YAAY,OAAO,CAAC,CAAA,OAAQ,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC,MAAM;IAC5D;IAEA,MAAa,eAAe,SAAiB,EAAoB;QAC/D,sBAAsB;QACtB,MAAM,aAAa,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC;QAE3C,sBAAsB;QACtB,MAAM,cAAuB;YAC3B,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,gBAAgB,IAAI;YACpC,MAAM;YACN,QAAQ;YACR,WAAW,IAAI;YACf,QAAQ;QACV;QAEA,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC;QAEnB,wBAAwB;QACxB,MAAM,kBAAkB,IAAI,CAAC,iBAAiB,CAAC,gBAAgB,CAAC,WAAW;QAC3E,MAAM,YAAY,IAAI,CAAC,SAAS,CAAC,QAAQ,CAAC;QAE1C,MAAM,aAAsB;YAC1B,IAAI,CAAC,IAAI,EAAE,IAAI,CAAC,gBAAgB,IAAI;YACpC,MAAM;YACN,QAAQ;YACR,WAAW,IAAI;YACf,QAAQ;QACV;QAEA,IAAI,CAAC,QAAQ,CAAC,IAAI,CAAC;QAEnB,OAAO;IACT;IAEO,cAAyB;QAC9B,OAAO;eAAI,IAAI,CAAC,QAAQ;SAAC;IAC3B;IAEO,eAA0B;QAC/B,OAAO,IAAI,CAAC,SAAS;IACvB;IAEO,qBAOL;QACA,MAAM,YAAY,IAAI,CAAC,QAAQ,CAAC,OAAO,CAAC,CAAA,MAAO,IAAI,MAAM;QACzD,MAAM,aAAa,UAAU,MAAM,CAAC,CAAC,KAAK;YACxC,GAAG,CAAC,MAAM,IAAI,CAAC,GAAG,CAAC,GAAG,CAAC,MAAM,IAAI,CAAC,IAAI,CAAC,IAAI;YAC3C,OAAO;QACT,GAAG,CAAC;QAEJ,OAAO;YACL,MAAM,IAAI,CAAC,SAAS,CAAC,YAAY;YACjC,SAAS,IAAI,CAAC,SAAS,CAAC,SAAS,CAAC,YAAY;YAC9C,eAAe,WAAW,OAAO,IAAI;YACrC,YAAY,WAAW,IAAI,IAAI;YAC/B,mBAAmB,WAAW,WAAW,IAAI;YAC7C,cAAc,WAAW,MAAM,IAAI;QACrC;IACF;IAEO,qBAA6B;QAClC,OAAO,KAAK,SAAS,CAAC,IAAI,CAAC,QAAQ,EAAE,MAAM;IAC7C;IAEO,oBAA0B;QAC/B,IAAI,CAAC,QAAQ,GAAG,EAAE;QAClB,IAAI,CAAC,gBAAgB,GAAG;IAC1B;AACF;AAGO,eAAe;IACpB,MAAM,UAAU,IAAI,UAAU;QAC5B,cAAc;QACd,eAAe;IACjB;IAEA,QAAQ,GAAG,CAAC;IACZ,QAAQ,GAAG,CAAC,oBAAoB,QAAQ,kBAAkB,GAAG,IAAI;IAEjE,wBAAwB;IACxB,MAAM,eAAe;QACnB;QACA;QACA;QACA;QACA;KACD;IAED,KAAK,MAAM,WAAW,aAAc;QAClC,QAAQ,GAAG,CAAC,CAAC,QAAQ,EAAE,SAAS;QAChC,MAAM,WAAW,MAAM,QAAQ,cAAc,CAAC;QAC9C,QAAQ,GAAG,CAAC,CAAC,KAAK,EAAE,SAAS,IAAI,EAAE;QACnC,QAAQ,GAAG,CAAC,CAAC,SAAS,EAAE,SAAS,MAAM,CAAC,GAAG,CAAC,CAAA,IAAK,GAAG,EAAE,IAAI,CAAC,CAAC,EAAE,EAAE,IAAI,CAAC,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM,CAAC,CAAC;IACxF;IAEA,QAAQ,GAAG,CAAC;IACZ,MAAM,QAAQ,QAAQ,kBAAkB;IACxC,QAAQ,GAAG,CAAC,CAAC,kBAAkB,EAAE,MAAM,IAAI,CAAC,CAAC,EAAE,MAAM,OAAO,EAAE;IAC9D,QAAQ,GAAG,CAAC,CAAC,aAAa,EAAE,MAAM,UAAU,EAAE;IAC9C,QAAQ,GAAG,CAAC,CAAC,gBAAgB,EAAE,MAAM,aAAa,EAAE;IACpD,QAAQ,GAAG,CAAC,CAAC,oBAAoB,EAAE,MAAM,iBAAiB,EAAE;IAC5D,QAAQ,GAAG,CAAC,CAAC,eAAe,EAAE,MAAM,YAAY,EAAE;IAElD,OAAO;AACT;AAGO,MAAM,mBAAmB,IAAI;AAG7B,SAAS,SAAS,IAAY;IACnC,OAAO,iBAAiB,QAAQ,CAAC;AACnC;AAEA,wBAAwB;AACxB,IAAI,iDAAmB,eAAe,0DAAQ,IAAI,KAAK,QAAQ;IAC7D,aAAa,KAAK,CAAC,QAAQ,KAAK;AAClC","debugId":null}},
    {"offset": {"line": 429, "column": 0}, "map": {"version":3,"sources":["file:///Users/plana/Desktop/test/src/app/chat/route.ts"],"sourcesContent":["// src/app/chat/route.ts\nimport { NextRequest, NextResponse } from 'next/server';\n\n// Only import what actually exists and is properly exported\n// We'll start with a working version and add imports as we fix the lib files\n\ninterface ChatRequest {\n  message: string;\n  useLocalModel?: boolean;\n}\n\ninterface ChatResponse {\n  reply: string;\n  timestamp: string;\n  source: 'openai' | 'huggingface' | 'local' | 'fallback';\n}\n\n// Now we can import the properly structured lib files\nimport { ChatBot } from '../../lib/chatbot';\nimport { trainChatBot } from '../../lib/training';\nimport { tokenize } from '../../lib/tokenizer';\n\n// Initialize your local chatbot\nlet localChatBot: ChatBot | null = null;\n\nasync function initializeLocalChatBot() {\n  // For now, return null until we fix the lib files\n  // if (!localChatBot) {\n  //   try {\n  //     localChatBot = new ChatBot();\n  //     await processTrainingData();\n  //     console.log('Local chatbot initialized successfully');\n  //   } catch (error) {\n  //     console.error('Failed to initialize local chatbot:', error);\n  //     localChatBot = null;\n  //   }\n  // }\n  return null; // Temporary\n}\n\n// Option 1: Using OpenAI API (requires API key)\nasync function getOpenAIResponse(message: string): Promise<string> {\n  try {\n    const response = await fetch('https://api.openai.com/v1/chat/completions', {\n      method: 'POST',\n      headers: {\n        'Authorization': `Bearer ${process.env.OPENAI_API_KEY}`,\n        'Content-Type': 'application/json',\n      },\n      body: JSON.stringify({\n        model: 'gpt-3.5-turbo',\n        messages: [\n          {\n            role: 'system',\n            content: 'You are a casual, nonchalant AI assistant. Keep responses short and chill. Use lowercase and casual language.'\n          },\n          {\n            role: 'user',\n            content: message\n          }\n        ],\n        max_tokens: 150,\n        temperature: 0.7,\n      }),\n    });\n\n    if (!response.ok) {\n      throw new Error(`OpenAI API error: ${response.status}`);\n    }\n\n    const data = await response.json();\n    return data.choices[0]?.message?.content || \"couldn't process that rn\";\n  } catch (error) {\n    console.error('OpenAI API error:', error);\n    throw error;\n  }\n}\n\n// Option 2: Using Hugging Face API (free tier available)\nasync function getHuggingFaceResponse(message: string): Promise<string> {\n  try {\n    const response = await fetch(\n      'https://api-inference.huggingface.co/models/microsoft/DialoGPT-medium',\n      {\n        method: 'POST',\n        headers: {\n          'Authorization': `Bearer ${process.env.HUGGINGFACE_API_KEY}`,\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          inputs: message,\n          parameters: {\n            max_length: 100,\n            temperature: 0.8,\n          }\n        }),\n      }\n    );\n\n    if (!response.ok) {\n      throw new Error(`Hugging Face API error: ${response.status}`);\n    }\n\n    const data = await response.json();\n    return data.generated_text || \"hmm not sure about that\";\n  } catch (error) {\n    console.error('Hugging Face API error:', error);\n    throw error;\n  }\n}\n\n// Option 3: Using your local chatbot\nasync function getLocalResponse(message: string): Promise<string> {\n  try {\n    const chatbot = await initializeLocalChatBot();\n    if (!chatbot) {\n      throw new Error('Local chatbot not available');\n    }\n\n    // Tokenize the input message (for logging/debugging)\n    const tokens = tokenize(message);\n    console.log('Tokenized input:', tokens.map(t => t.text));\n    \n    // Generate response using your local model\n    const response = await chatbot.generateResponse(message);\n    \n    return response || \"my brain is still learning, try again\";\n  } catch (error) {\n    console.error('Local chatbot error:', error);\n    throw error;\n  }\n}\n\n// Option 4: Enhanced pattern matching with more comprehensive responses\nfunction getSmartResponse(message: string): string {\n  const msg = message.toLowerCase();\n  \n  // Math questions\n  if (msg.includes('what is') && (msg.includes('+') || msg.includes('-') || msg.includes('*') || msg.includes('/'))) {\n    try {\n      const mathExpression = msg.match(/[\\d\\+\\-\\*\\/\\.\\s]+/)?.[0];\n      if (mathExpression) {\n        // Safe math evaluation\n        const sanitized = mathExpression.replace(/[^0-9+\\-*/().]/g, '');\n        const result = Function('\"use strict\"; return (' + sanitized + ')')();\n        return `that's ${result}`;\n      }\n    } catch {\n      return \"math isn't my strong suit\";\n    }\n  }\n  \n  // Science questions\n  if (msg.includes('what is') || msg.includes('explain') || msg.includes('how does')) {\n    const scienceTopics = {\n      'gravity': \"gravity pulls stuff down, pretty simple\",\n      'photosynthesis': \"plants eat sunlight basically\",\n      'dna': \"genetic code that makes you... you\",\n      'evolution': \"things change over time to survive better\",\n      'quantum': \"tiny particles doing weird stuff\",\n      'atoms': \"super small building blocks of everything\",\n      'solar system': \"sun and planets doing their orbit thing\",\n      'black hole': \"space vacuum that sucks everything in\",\n    };\n    \n    for (const [topic, explanation] of Object.entries(scienceTopics)) {\n      if (msg.includes(topic)) {\n        return explanation;\n      }\n    }\n  }\n  \n  // Programming questions\n  if (msg.includes('code') || msg.includes('programming') || msg.includes('javascript') || msg.includes('python')) {\n    return \"coding is cool, what specifically do you need help with?\";\n  }\n  \n  // General knowledge\n  if (msg.includes('who is') || msg.includes('who was')) {\n    return \"probably someone famous, idk google it\";\n  }\n  \n  if (msg.includes('when') || msg.includes('what year')) {\n    return \"sometime in the past probably\";\n  }\n  \n  if (msg.includes('where is') || msg.includes('where was')) {\n    return \"somewhere on earth i'd guess\";\n  }\n  \n  if (msg.includes('why') || msg.includes('how come')) {\n    return \"that's just how things work sometimes\";\n  }\n  \n  // Advice/opinion questions\n  if (msg.includes('should i') || msg.includes('what do you think')) {\n    const advice = [\n      \"eh, do whatever feels right\",\n      \"you probably know better than me\",\n      \"follow your gut i guess\",\n      \"could go either way tbh\",\n      \"up to you really\"\n    ];\n    return advice[Math.floor(Math.random() * advice.length)];\n  }\n  \n  // Default responses\n  const defaultResponses = [\n    \"interesting question, not sure though\",\n    \"that's above my pay grade\",\n    \"good question, wish i knew\",\n    \"hmm, that's a tough one\",\n    \"you got me there\",\n    \"not really my area of expertise\",\n    \"probably google knows better than me\"\n  ];\n  \n  return defaultResponses[Math.floor(Math.random() * defaultResponses.length)];\n}\n\nexport async function POST(request: NextRequest) {\n  try {\n    const body: ChatRequest = await request.json();\n    \n    if (!body.message || typeof body.message !== 'string') {\n      return NextResponse.json(\n        { error: 'Message is required and must be a string' },\n        { status: 400 }\n      );\n    }\n\n    // Add realistic delay\n    await new Promise(resolve => setTimeout(resolve, 300 + Math.random() * 700));\n\n    let reply: string;\n    let source: ChatResponse['source'] = 'fallback';\n\n    try {\n      // Priority order for getting responses\n      if (body.useLocalModel) {\n        // Force use of local model if requested (currently disabled)\n        try {\n          reply = await getLocalResponse(body.message);\n          source = 'local';\n        } catch (localError) {\n          console.log('Local model not available, using fallback');\n          reply = getSmartResponse(body.message);\n          source = 'fallback';\n        }\n      } else if (process.env.OPENAI_API_KEY) {\n        reply = await getOpenAIResponse(body.message);\n        source = 'openai';\n      } else if (process.env.HUGGINGFACE_API_KEY) {\n        reply = await getHuggingFaceResponse(body.message);\n        source = 'huggingface';\n      } else {\n        // Fallback to pattern matching\n        reply = getSmartResponse(body.message);\n        source = 'fallback';\n      }\n    } catch (error) {\n      console.error('Primary response method failed:', error);\n      // Fallback to pattern matching\n      reply = getSmartResponse(body.message);\n      source = 'fallback';\n    }\n\n    const response: ChatResponse = {\n      reply,\n      timestamp: new Date().toISOString(),\n      source\n    };\n\n    return NextResponse.json(response);\n    \n  } catch (error) {\n    console.error('Chat API error:', error);\n    return NextResponse.json(\n      { error: 'something went wrong, my bad' },\n      { status: 500 }\n    );\n  }\n}\n\nexport async function GET() {\n  return NextResponse.json(\n    { \n      message: 'ai is ready to answer stuff',\n      availableSources: {\n        openai: !!process.env.OPENAI_API_KEY,\n        huggingface: !!process.env.HUGGINGFACE_API_KEY,\n        local: true, // Now available!\n        fallback: true\n      }\n    },\n    { status: 200 }\n  );\n}"],"names":[],"mappings":"AAAA,wBAAwB;;;;;AACxB;AAmBA;;;AAEA,gCAAgC;AAChC,IAAI,eAA+B;AAEnC,eAAe;IACb,kDAAkD;IAClD,uBAAuB;IACvB,UAAU;IACV,oCAAoC;IACpC,mCAAmC;IACnC,6DAA6D;IAC7D,sBAAsB;IACtB,mEAAmE;IACnE,2BAA2B;IAC3B,MAAM;IACN,IAAI;IACJ,OAAO,MAAM,YAAY;AAC3B;AAEA,gDAAgD;AAChD,eAAe,kBAAkB,OAAe;IAC9C,IAAI;QACF,MAAM,WAAW,MAAM,MAAM,8CAA8C;YACzE,QAAQ;YACR,SAAS;gBACP,iBAAiB,CAAC,OAAO,EAAE,QAAQ,GAAG,CAAC,cAAc,EAAE;gBACvD,gBAAgB;YAClB;YACA,MAAM,KAAK,SAAS,CAAC;gBACnB,OAAO;gBACP,UAAU;oBACR;wBACE,MAAM;wBACN,SAAS;oBACX;oBACA;wBACE,MAAM;wBACN,SAAS;oBACX;iBACD;gBACD,YAAY;gBACZ,aAAa;YACf;QACF;QAEA,IAAI,CAAC,SAAS,EAAE,EAAE;YAChB,MAAM,IAAI,MAAM,CAAC,kBAAkB,EAAE,SAAS,MAAM,EAAE;QACxD;QAEA,MAAM,OAAO,MAAM,SAAS,IAAI;QAChC,OAAO,KAAK,OAAO,CAAC,EAAE,EAAE,SAAS,WAAW;IAC9C,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,qBAAqB;QACnC,MAAM;IACR;AACF;AAEA,yDAAyD;AACzD,eAAe,uBAAuB,OAAe;IACnD,IAAI;QACF,MAAM,WAAW,MAAM,MACrB,yEACA;YACE,QAAQ;YACR,SAAS;gBACP,iBAAiB,CAAC,OAAO,EAAE,QAAQ,GAAG,CAAC,mBAAmB,EAAE;gBAC5D,gBAAgB;YAClB;YACA,MAAM,KAAK,SAAS,CAAC;gBACnB,QAAQ;gBACR,YAAY;oBACV,YAAY;oBACZ,aAAa;gBACf;YACF;QACF;QAGF,IAAI,CAAC,SAAS,EAAE,EAAE;YAChB,MAAM,IAAI,MAAM,CAAC,wBAAwB,EAAE,SAAS,MAAM,EAAE;QAC9D;QAEA,MAAM,OAAO,MAAM,SAAS,IAAI;QAChC,OAAO,KAAK,cAAc,IAAI;IAChC,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,2BAA2B;QACzC,MAAM;IACR;AACF;AAEA,qCAAqC;AACrC,eAAe,iBAAiB,OAAe;IAC7C,IAAI;QACF,MAAM,UAAU,MAAM;QACtB,wCAAc;YACZ,MAAM,IAAI,MAAM;QAClB;QAEA,qDAAqD;QACrD,MAAM,SAAS,CAAA,GAAA,yHAAA,CAAA,WAAQ,AAAD,EAAE;QACxB,QAAQ,GAAG,CAAC,oBAAoB,OAAO,GAAG,CAAC,CAAA,IAAK,EAAE,IAAI;QAEtD,2CAA2C;QAC3C,MAAM,WAAW,MAAM,QAAQ,gBAAgB,CAAC;QAEhD,OAAO,YAAY;IACrB,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wBAAwB;QACtC,MAAM;IACR;AACF;AAEA,wEAAwE;AACxE,SAAS,iBAAiB,OAAe;IACvC,MAAM,MAAM,QAAQ,WAAW;IAE/B,iBAAiB;IACjB,IAAI,IAAI,QAAQ,CAAC,cAAc,CAAC,IAAI,QAAQ,CAAC,QAAQ,IAAI,QAAQ,CAAC,QAAQ,IAAI,QAAQ,CAAC,QAAQ,IAAI,QAAQ,CAAC,IAAI,GAAG;QACjH,IAAI;YACF,MAAM,iBAAiB,IAAI,KAAK,CAAC,sBAAsB,CAAC,EAAE;YAC1D,IAAI,gBAAgB;gBAClB,uBAAuB;gBACvB,MAAM,YAAY,eAAe,OAAO,CAAC,mBAAmB;gBAC5D,MAAM,SAAS,SAAS,2BAA2B,YAAY;gBAC/D,OAAO,CAAC,OAAO,EAAE,QAAQ;YAC3B;QACF,EAAE,OAAM;YACN,OAAO;QACT;IACF;IAEA,oBAAoB;IACpB,IAAI,IAAI,QAAQ,CAAC,cAAc,IAAI,QAAQ,CAAC,cAAc,IAAI,QAAQ,CAAC,aAAa;QAClF,MAAM,gBAAgB;YACpB,WAAW;YACX,kBAAkB;YAClB,OAAO;YACP,aAAa;YACb,WAAW;YACX,SAAS;YACT,gBAAgB;YAChB,cAAc;QAChB;QAEA,KAAK,MAAM,CAAC,OAAO,YAAY,IAAI,OAAO,OAAO,CAAC,eAAgB;YAChE,IAAI,IAAI,QAAQ,CAAC,QAAQ;gBACvB,OAAO;YACT;QACF;IACF;IAEA,wBAAwB;IACxB,IAAI,IAAI,QAAQ,CAAC,WAAW,IAAI,QAAQ,CAAC,kBAAkB,IAAI,QAAQ,CAAC,iBAAiB,IAAI,QAAQ,CAAC,WAAW;QAC/G,OAAO;IACT;IAEA,oBAAoB;IACpB,IAAI,IAAI,QAAQ,CAAC,aAAa,IAAI,QAAQ,CAAC,YAAY;QACrD,OAAO;IACT;IAEA,IAAI,IAAI,QAAQ,CAAC,WAAW,IAAI,QAAQ,CAAC,cAAc;QACrD,OAAO;IACT;IAEA,IAAI,IAAI,QAAQ,CAAC,eAAe,IAAI,QAAQ,CAAC,cAAc;QACzD,OAAO;IACT;IAEA,IAAI,IAAI,QAAQ,CAAC,UAAU,IAAI,QAAQ,CAAC,aAAa;QACnD,OAAO;IACT;IAEA,2BAA2B;IAC3B,IAAI,IAAI,QAAQ,CAAC,eAAe,IAAI,QAAQ,CAAC,sBAAsB;QACjE,MAAM,SAAS;YACb;YACA;YACA;YACA;YACA;SACD;QACD,OAAO,MAAM,CAAC,KAAK,KAAK,CAAC,KAAK,MAAM,KAAK,OAAO,MAAM,EAAE;IAC1D;IAEA,oBAAoB;IACpB,MAAM,mBAAmB;QACvB;QACA;QACA;QACA;QACA;QACA;QACA;KACD;IAED,OAAO,gBAAgB,CAAC,KAAK,KAAK,CAAC,KAAK,MAAM,KAAK,iBAAiB,MAAM,EAAE;AAC9E;AAEO,eAAe,KAAK,OAAoB;IAC7C,IAAI;QACF,MAAM,OAAoB,MAAM,QAAQ,IAAI;QAE5C,IAAI,CAAC,KAAK,OAAO,IAAI,OAAO,KAAK,OAAO,KAAK,UAAU;YACrD,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;gBAAE,OAAO;YAA2C,GACpD;gBAAE,QAAQ;YAAI;QAElB;QAEA,sBAAsB;QACtB,MAAM,IAAI,QAAQ,CAAA,UAAW,WAAW,SAAS,MAAM,KAAK,MAAM,KAAK;QAEvE,IAAI;QACJ,IAAI,SAAiC;QAErC,IAAI;YACF,uCAAuC;YACvC,IAAI,KAAK,aAAa,EAAE;gBACtB,6DAA6D;gBAC7D,IAAI;oBACF,QAAQ,MAAM,iBAAiB,KAAK,OAAO;oBAC3C,SAAS;gBACX,EAAE,OAAO,YAAY;oBACnB,QAAQ,GAAG,CAAC;oBACZ,QAAQ,iBAAiB,KAAK,OAAO;oBACrC,SAAS;gBACX;YACF,OAAO,IAAI,QAAQ,GAAG,CAAC,cAAc,EAAE;gBACrC,QAAQ,MAAM,kBAAkB,KAAK,OAAO;gBAC5C,SAAS;YACX,OAAO,IAAI,QAAQ,GAAG,CAAC,mBAAmB,EAAE;gBAC1C,QAAQ,MAAM,uBAAuB,KAAK,OAAO;gBACjD,SAAS;YACX,OAAO;gBACL,+BAA+B;gBAC/B,QAAQ,iBAAiB,KAAK,OAAO;gBACrC,SAAS;YACX;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,mCAAmC;YACjD,+BAA+B;YAC/B,QAAQ,iBAAiB,KAAK,OAAO;YACrC,SAAS;QACX;QAEA,MAAM,WAAyB;YAC7B;YACA,WAAW,IAAI,OAAO,WAAW;YACjC;QACF;QAEA,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CAAC;IAE3B,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,mBAAmB;QACjC,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;YAAE,OAAO;QAA+B,GACxC;YAAE,QAAQ;QAAI;IAElB;AACF;AAEO,eAAe;IACpB,OAAO,gIAAA,CAAA,eAAY,CAAC,IAAI,CACtB;QACE,SAAS;QACT,kBAAkB;YAChB,QAAQ,CAAC,CAAC,QAAQ,GAAG,CAAC,cAAc;YACpC,aAAa,CAAC,CAAC,QAAQ,GAAG,CAAC,mBAAmB;YAC9C,OAAO;YACP,UAAU;QACZ;IACF,GACA;QAAE,QAAQ;IAAI;AAElB","debugId":null}}]
}